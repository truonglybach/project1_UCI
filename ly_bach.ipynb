{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing\n",
    "## Overview\n",
    "\n",
    "When looking through datasets that contain over 20,000 instances of housing data, it would be very unlikely to not wonder about the insights that the data may possibly hold.\n",
    "\n",
    "One may ask:\n",
    "- What if you wanted to get rich off of real estate?\n",
    "- What if you wanted to predict the next housing bubble?\n",
    "- What if you could produce invaluable insights that could be the basis for further research?\n",
    "\n",
    "Although the first two out of the three speculations are unlikely to result from just reading into our two datasets, it would be a waste to not break these chunks of information apart and see what we can get, but before we delve deep into our datasets, we should consider the limitations of our data.\n",
    "\n",
    "1. The Kaggle dataset (\"housing.csv\") is an extracted (but not cleaned) version of the California 1990 Census and it holds median and total numerical values for housing features per district, separated by latitudinal and longitudinal coordinates. Kaggle is an online community platform for data enthusiasts. This dataset is a modified version from data that was gathered by associate professor, Luis Torgo, from the University of Porto, whom of which had collected the data from the California Census of 1990.\n",
    "\n",
    "2. The recent housing listings data (\"Total.csv\"), which were posted from up to a year since 19 September 2018, only shows listings that are posted by real estate brokers on an industry-accepted information dissemination system, the California Regional Multiple Listing Service (CRMLS); therefore, off-market listings <u>are not</u> represented in the data.\n",
    "\n",
    "Although there are some lingering questions that lay underneath our data (considering how it was obtained) and our resources are limited as to how accurately we can produce our analyses, we still are tasked to come to a data-driven conclusion to find out the answer to the following question:\n",
    "\n",
    "If we took the top and bottom five percentiles of houses in California during the 1990s, in terms of median house value, and compared them to houses of the same standing that have been listed for sale within the last year in the same market, would there be a statistical difference between the two groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up and getting our hands dirty with the data\n",
    "Before we can extract any meaningful and accurate analyses from our data, we must first make an attempt to understand all of its facets and not just search for whatever we want; that means, we must first 'get our hands dirty' with it. Although it can be irresistably fun just to mess around with our data, we should be aware that there is a more valuable incentive for doing so, which is described by the XY Problem.\n",
    "\n",
    "** For further reasoning, please refer to the following link to a discussion which details the XY Problem: https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to easily work with our data, we must first import the necessary dependencies and store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import gmplot\n",
    "import scipy as stats\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/store data\n",
    "ca_1990 = pd.read_csv('Data/housing.csv')\n",
    "ca_current = pd.read_csv('Data/Total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total instances are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1990.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's drop the rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1990 = ca_1990.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1990.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason for dropping values\n",
    "There is an approximate 1% difference when rows with any empty values are dropped and the data is derived as the median of each of its categories per the district; therefore, the values are negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing (1990) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Search for Relationships\n",
    "We were looking at the several features that was listed within our data (such as the longitudinal and latitudinal coordinates of each district, the median ages of the houses, the total number of rooms, and so forth)  and made several charts in an attempt to draw insights which may be lying underneath, and they are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Rooms per District vs Total Population District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "group_names = [\"<5k\", \"5k-10k\", \"10k-15k\", \"15k-20k\", \"20k-25k\", \"25k-30k\", \"30k-35k\", \">35k\"]\n",
    "ca_1990[\"total_rooms_groups\"] = pd.cut(ca_1990['total_rooms'], bins, labels=group_names)\n",
    "\n",
    "plt.scatter(ca_1990['total_rooms_groups'], ca_1990['population'])\n",
    "plt.xlabel('Total Rooms')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Total Rooms per District vs Population per District')\n",
    "plt.grid()\n",
    "plt.savefig(\"pngs/pop_vs_rooms_sub_groups.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The chart above depicts the frequencies for several ranges of number of total rooms per the district and is set against the total population of a district.*\n",
    "* *It is intriguing to see that there is a concentration of districts that have zero to twenty thousand rooms and populations from zero to thirteen thousand.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Five Percent of Median House Values vs Total Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slice the top 5%\n",
    "top5 = ca_1990.iloc[:round(len(ca_1990['median_house_value'])*0.05), :].sort_values('median_house_value', ascending=False)\n",
    "top5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 13000]\n",
    "group_names = [\"<1k\", \"1k-2k\", \"2k-3k\", \"3k-4k\", \"4k-5k\", \"5k-6k\", \"6k-7k\", \">7k\"]\n",
    "top5['population_groups'] = pd.cut(top5['population'], bins, labels=group_names)\n",
    "top5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(top5['median_house_value'], top5['population_groups'], c='r')\n",
    "plt.xlabel('House Value')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Total Population vs Median House Value')\n",
    "plt.grid()\n",
    "plt.savefig(\"pngs/Top5_PHV.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *From the plot above, we can see that there is a general concentration in districts with populations ranging from zero to two thousand people per district, in respect to houses that rank in the top five percentile in terms of median house value.*\n",
    "* *We can infer from this data that districts with this general range of population is ubiquitous and non-dependent of median house value.*\n",
    "* *Intriguingly, we can see that houses that are worth approximately five hundred thousand dollars can vary from small to large numbers of population.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom Five Percent of Median House Values vs Total Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slice the bottom 5%\n",
    "bottom5 = ca_1990.iloc[round(len(ca_1990['median_house_value'])*0.95): len(ca_1990['median_house_value']),:].sort_values('median_house_value', ascending=False)\n",
    "bottom5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 3000, 6000, 9000, 12000, 15000, 18000]\n",
    "group_names = [\"<3k\", \"3k-6k\", \"6k-9k\", \"9k-12k\", \"12k-15k\", \">15k\"]\n",
    "bottom5[\"population_groups\"] = pd.cut(bottom5['population'], bins, labels=group_names)\n",
    "plt.scatter(bottom5['median_house_value'], bottom5['population_groups'], c='g')\n",
    "plt.xlabel('House Value')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Total Population vs Median House Value')\n",
    "plt.grid()\n",
    "plt.savefig('pngs/Bottom5_PHV.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *From the plot above, we can see that there is a general concentration in districts with populations ranging from zero to three thousand people per district and from three to six thousand people per district, in respect to houses that rank in the bottom five percentile in terms of median house value.*\n",
    "* *We can infer from this data that districts with these general ranges of populations are ubiquitous and non-dependent of median house value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ocean Proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort data by house value\n",
    "ca_1990 = ca_1990.sort_values('median_house_value', ascending=False).reset_index(drop=True)\n",
    "ca_1990.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ocean Proximity vs Count of Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_axis_op = [\"<1H OCEAN\", \"INLAND\", \"ISLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
    "y_axis_op = ca_1990.groupby(\"ocean_proximity\").count().rename(columns={\"longitude\": \"count_of_houses\"})[\"count_of_houses\"]\n",
    "plt.bar(x_axis_op, y_axis_op, alpha=0.5, align='center')\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Count of Houses\")\n",
    "op_bar_chart = plt.title(\"Total Number of Houses in CA per OP Category\")\n",
    "plt.savefig('pngs/op_vs_count_of_houses.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The bar chart above depicts the total count of houses per each category.*\n",
    "* *We can see that most of the houses in California are either less than one-hour away from the ocean or are inland.*\n",
    "* *The chart also communicates that the majority of Californians lived less than one hour from the ocean during the 1990s.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_op = [\"<1H OCEAN\", \"INLAND\", \"NEAR BAY\"]\n",
    "y_axis_op = top5.groupby(\"ocean_proximity\").count().rename(columns={\"longitude\": \"count_of_houses\"})[\"count_of_houses\"]\n",
    "plt.bar(x_axis_op, y_axis_op, color='b', alpha=0.5, align='center')\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Count of Houses\")\n",
    "op_bar_chart = plt.title(\"Top Five Percent\")\n",
    "plt.savefig(\"pngs/top_five_op_vs_COH.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Percent Ocean Proximity vs Count of Houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The chart above shows the total count of houses per ocean proximity category for houses in the top five percent, in terms of median house value.*\n",
    "* *The majority of these houses are in closer proximity to some body of water than houses that are inland.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom 5 Percent Ocean Proximity vs Count of Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_op = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\"]\n",
    "y_axis_op = bottom5.groupby(\"ocean_proximity\").count().rename(columns={\"longitude\": \"count_of_houses\"})[\"count_of_houses\"]\n",
    "plt.bar(x_axis_op, y_axis_op, color='g', alpha=0.5, align='center')\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Count of Houses\")\n",
    "op_bar_chart = plt.title(\"Bottom Five Percent\")\n",
    "plt.savefig(\"pngs/bottom_five_op_vs_COH.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The chart above depicts the total count of houses per ocean proximity category for houses in the bottom five percent, in terms of median house value.*\n",
    "* *The majority of these houses are inland; furthest from any body of water in comparison to their counterparts.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Five Ocean Proximity Average Median Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_mean_house_value_top = top5.groupby(\"ocean_proximity\")[\"median_house_value\"].mean().round(2)\n",
    "op_mean_df_top = pd.DataFrame(op_mean_house_value_top)\n",
    "op_mean_df_top = op_mean_df_top.rename(columns={\"median_house_value\":\"Average Median Price\"})\n",
    "op_mean_df_top['Average Median Price'] = op_mean_df_top['Average Median Price'].map('${:,.2f}'.format)\n",
    "op_mean_df_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Although we expect that being located closer to bodies of water usually translates to a higher price per house, the averages of the median values for our top five percent of houses in California have similar prices.*\n",
    "* *Intriguingly, the inland category has an average value that is higher than any of the other categories, which are all nearer to some body of water.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom Five Ocean Proximity Average Median Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_mean_house_value_bottom = bottom5.groupby(\"ocean_proximity\")[\"median_house_value\"].mean().round(2)\n",
    "op_mean_df_bottom = pd.DataFrame(op_mean_house_value_bottom)\n",
    "op_mean_df_bottom = op_mean_df_bottom.rename(columns={\"median_house_value\":\"Average Median Price\"})\n",
    "op_mean_df_bottom['Average Median Price'] = op_mean_df_bottom['Average Median Price'].map('${:,.2f}'.format)\n",
    "op_mean_df_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Again, we expect that being located closer to bodies of water would translate to a higher price per house, the averages of the median values for our bottom five percent of houses in California deviates from our assumptions.*\n",
    "* *The same surprise is evident in this data, when compared to its opposite counterpart.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing (2018) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns that are useful \n",
    "ca_current = ca_current[['Sub Type', 'St#', 'St Name', 'City', 'L/C Price', 'Br/Ba', 'YrBuilt']]\n",
    "ca_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *We cleaned our data frame of any superfluous information, as either some are not quantifiable or we simply cannot work with them due to our limited sets of data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Housing Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating for the age, we must check for any missing values that lay in our YrBuilt column and the count of all instances in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in ca_current['YrBuilt'].isna():\n",
    "    if i == True:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_current.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ca_current.count().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also must calculate the number of values dropped if we were to delete all rows with any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_current.dropna().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Here, we encounter something strange. Even though our for loop above states that there are 8 NaN values underneath the YrBuilt columns, when we drop all rows with any missing value, the total number of rows dropped is only 4.*\n",
    "* *If we continue to attempt with a new dataframe that utilizes the .dropna() method, we will find that there is a bug in which most values become missing; therefore, we must fill all missing values with 0 in order to solve our issue.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the string to isolate the integers\n",
    "yr_blt = ca_current.loc[:, 'YrBuilt'].str.split('/', expand=True)[0]\n",
    "# Turn the values into a data frame\n",
    "yr_blt = pd.DataFrame(yr_blt)\n",
    "# Fill the empty cells with 0\n",
    "yr_blt = yr_blt.fillna(0)\n",
    "# Create the new columns for age\n",
    "ca_current['Age'] = ''\n",
    "# Calculate for age\n",
    "count = 0\n",
    "for i in yr_blt[0]:\n",
    "    # Values that were empty are now 0 years old.\n",
    "    # We will count them later to determine whether or not we will drop them.\n",
    "    i = 2018 - int(i)\n",
    "    ca_current['Age'][count] = i\n",
    "    count += 1\n",
    "ca_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *In the data frame above, we are calculating the current ages of our houses by subtracting the current year from the year they were built.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of NaN Values under YrBuilt column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grab all values with the year 2018 since 2018 - 0 = 2018\n",
    "with_nan_df = ca_current.loc[ca_current['Age'] == 2018, :]\n",
    "# Grab the values that are not NaN, but built in 2018\n",
    "zero_bld = with_nan_df.loc[with_nan_df['YrBuilt'] == '0/BLD', :]\n",
    "zero_asr = with_nan_df.loc[with_nan_df['YrBuilt'] == '0/ASR', :]\n",
    "# Remove the houses that are built in 2018 and merge the necessary data frames\n",
    "without_2018_df = pd.merge(ca_current, with_nan_df, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "with_zero_bld = pd.merge(without_2018_df, zero_bld, how='outer')\n",
    "zero_asr['Age'] = zero_asr['Age'].apply(int)\n",
    "without_nan_df = pd.merge(with_zero_bld, zero_asr, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the house prices without the dollar sign \n",
    "without_nan_df['house_price'] = without_nan_df.loc[:, 'L/C Price'].str.split('$', expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_nan_df['house_price'] = without_nan_df['house_price'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data frame and set the index to the listing price\n",
    "sorted_ca_current = ca_current.set_index(\"L/C Price\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort data by median house value and slice the top and bottom 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the top 5%\n",
    "top5_2018 = sorted_ca_current.iloc[round(len(without_nan_df['house_price'])*0.95): len(without_nan_df['house_price']),:]\n",
    "top5_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the bottom 5%\n",
    "bottom5_2018 = without_nan_df.iloc[:round(len(without_nan_df['house_price'])*0.05), :]\n",
    "bottom5_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 1990 and 2018 House Data with Gmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorations\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import gmplot\n",
    "from config import api_key\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database\n",
    "df1 = pd.read_csv('Data/housing.csv')\n",
    "df2 = pd.read_csv('Data/Total.csv')\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing (1990) Gmap Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort and slice data to get top and bottom 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSort data by house value\n",
    "df1 = df1.sort_values('median_house_value', ascending=False).reset_index(drop=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the top 5%\n",
    "top5 = df1.iloc[:round(len(df1['median_house_value'])*0.05), :].sort_values('median_house_value', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the bottom 5%\n",
    "bottom5 = df1.iloc[round(len(df1['median_house_value'])*0.95): len(df1['median_house_value']),:].sort_values('median_house_value', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Top 5% and Bottom 5% on gmap (Use gmplot package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the center of the map\n",
    "gmap_df1 = gmplot.GoogleMapPlotter(df1['latitude'].median(),\n",
    "                                   df1['longitude'].median(), 100000)\n",
    "# Plot scatter points based on LatLng\n",
    "gmap_df1.scatter(df1['latitude'], df1['longitude'], '#FF0000', \n",
    "                              size = 2000, marker = False ) \n",
    "# Draw out to 'Plot' folder in html format\n",
    "gmap_df1.draw(\"gmap_df1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the center of the map\n",
    "gmap = gmplot.GoogleMapPlotter(top5['latitude'].median(),\n",
    "                                   top5['longitude'].median(), 100000)\n",
    "# Plot scatter points based on LatLng\n",
    "gmap.scatter(top5['latitude'], top5['longitude'], '#FF0000', \n",
    "                              size = 2000, marker = False ) \n",
    "gmap.scatter(bottom5['latitude'], bottom5['longitude'], '#110870', \n",
    "                              size = 2000, marker = False ) \n",
    "# Draw out to 'Plot' folder in html format\n",
    "gmap.draw(\"gmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Latitudinal and Longitudinal Coordinates using Geocoder API for 2018 Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns that are useful \n",
    "df2 = df2[['Sub Type', 'St#', 'St Name', 'City', 'L/C Price', 'Br/Ba', 'YrBuilt']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_blt = df2.loc[:, 'YrBuilt'].str.split('/', expand=True)[0]\n",
    "yr_blt = pd.DataFrame(yr_blt)\n",
    "yr_blt = yr_blt.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2['Age'] = ''\n",
    "count = 0\n",
    "for i in yr_blt[0]:\n",
    "        i = 2018 - int(i)\n",
    "        df2['Age'][count] = i\n",
    "        count += 1\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['house_price'] = df2.loc[:, 'L/C Price'].str.split('$', expand=True)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2_by_value = df2.set_index(\"L/C Price\")\n",
    "df2_by_value = df2_by_value.reset_index()\n",
    "df2_by_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CityCode\n",
    "citycode_df = pd.read_csv('Data/CleanCityCode_nospace.csv')\n",
    "citycode_df = citycode_df[['City', 'Code']]\n",
    "citycode_df['Code'] = citycode_df['Code'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_by_value['City Name'] = \"\"\n",
    "for index, row in df2_by_value.iterrows():\n",
    "    for i, r in citycode_df.iterrows():\n",
    "        if r['Code'] == row['City']:\n",
    "            row['City Name'] = r['City']\n",
    "            if index%200 == 0:\n",
    "                print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_by_value[\"Address\"] = df2_by_value[\"St#\"].astype(str) + \" \" + df2_by_value[\"St Name\"].astype(str) + \" \" + df2_by_value['City Name']\n",
    "df2_by_value['Lat'] = \"\"\n",
    "df2_by_value['Lng'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"key\": api_key}\n",
    "for index, row in df2_by_value.iterrows():\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params['address'] = row['Address']\n",
    "    geo_data = requests.get(base_url, params).json()\n",
    "    try:\n",
    "        df2_by_value[\"Lat\"][index] = geo_data[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        df2_by_value[\"Lng\"][index] = geo_data[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        if index%100 == 0:\n",
    "            print(index)\n",
    "    except IndexError:\n",
    "        print(f\"Row {index} cannot be found on gmap.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to CSV\n",
    "df2_by_value.to_csv(\"Data/df2_latlng.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing (2018) Gmap Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_latlng = pd.read_csv(\"Data/df2_latlng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_latlng = df2_latlng[['L/C Price','Lat', 'Lng']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_df2 = df2_latlng.iloc[:round(len(df2_latlng['L/C Price'])*0.05), :].sort_values('L/C Price', ascending=True)\n",
    "bottom5_df2 = df2_latlng.iloc[round(len(df2_latlng['L/C Price'])*0.95): len(df2_latlng['L/C Price']),:].sort_values('L/C Price', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the center of the map\n",
    "gmap_df2_tab = gmplot.GoogleMapPlotter(top5_df2['Lat'].median(),\n",
    "                                   top5_df2['Lng'].median(), 100000)\n",
    "# Plot scatter points based on LatLng\n",
    "gmap_df2_tab.scatter(top5_df2['Lat'], top5_df2['Lng'], '#FF0000', \n",
    "                              size = 2000, marker = False ) \n",
    "gmap_df2_tab.scatter(bottom5_df2['Lat'], bottom5_df2['Lng'], '#110870', \n",
    "                              size = 2000, marker = False ) \n",
    "# Draw out to 'Plot' folder in html format\n",
    "gmap_df2_tab.draw(\"Plot/gmap_df2_tab.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the center of the map\n",
    "gmap_df2 = gmplot.GoogleMapPlotter(df2_latlng['Lat'].median(),\n",
    "                                df2_latlng['Lng'].median(), 100)\n",
    "# Plot scatter points based on LatLng\n",
    "gmap_df2.scatter(df2_latlng['Lat'], df2_latlng['Lng'], '#FF0000', \n",
    "                              size = 1000, marker = False) \n",
    "# Draw out to 'Plot' folder in html format\n",
    "gmap_df2.draw(\"Plot/gmap_df2.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database\n",
    "df1 = pd.read_csv('Data/housing.csv')\n",
    "df2 = pd.read_csv('Data/Total.csv')\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSort data by house value\n",
    "df1 = df1.sort_values('median_house_value', ascending=False).reset_index(drop=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns that are useful \n",
    "df2 = df2[['Sub Type', 'St#', 'St Name', 'City', 'L/C Price', 'Br/Ba', 'YrBuilt']]\n",
    "df2.head()\n",
    "#df2 = df2.drop(on=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['house_price'] = df2.loc[:, 'L/C Price'].str.split('$', expand=True)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_by_value = df2.set_index(\"L/C Price\")\n",
    "df2_by_value = df2_by_value.reset_index()\n",
    "df2_by_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['L/C Price'] = df2['L/C Price'].str.strip('$')\n",
    "df2['L/C Price'] = df2['L/C Price'].str.replace(',', \"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df1['median_house_value']\n",
    "s2 = df2['L/C Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s1 = {'s1': s1}\n",
    "data_s1 = pd.DataFrame(data_s1)\n",
    "data_s2 = {'s2': s2}\n",
    "data_s2 = pd.DataFrame(data_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t_stat, p) = stats.ttest_ind(s1, s2, equal_var=False)\n",
    "print(\"t-statistics is {}.\".format(t_stat))\n",
    "print(\"p-value is {}.\".format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled_s1 = min_max_scaler.fit_transform(data_s1)\n",
    "np_scaled_s2 = min_max_scaler.fit_transform(data_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(t_stat, p) = stats.ttest_ind(np_scaled_s1, np_scaled_s2, equal_var=False)\n",
    "print(\"t-statistics is {}.\".format(t_stat))\n",
    "print(\"p-value is {}.\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusion\n",
    "We performed our t-test without normalization on the 1990 data set and 2018 data set, which gave us a p-value of 2.306824488018087e-15.\n",
    "This means that thereâ€™s no significant difference between the two datasets, which conveys that the distribution of the house prices of both data sets is similar. \n",
    "We then normalized the data and got a p-value of 0, which further proves that the distribution is similar.\n",
    "Overall, due to the fact that there is no statistical difference between the two data sets, the same factors that affected the prices of houses in California during the year of 1990 are very likely to still be significant in determining the prices of houses in California in the present day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
