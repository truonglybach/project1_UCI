{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing\n",
    "## Overview\n",
    "\n",
    "When looking through datasets that contain over 20,000 instances of housing data, it would be very unlikely to not wonder about the insights that the data may possibly hold.\n",
    "\n",
    "One may ask:\n",
    "- What if you wanted to get rich off of real estate?\n",
    "- What if you wanted to predict the next housing bubble?\n",
    "- What if you could produce invaluable insights that could be the basis for further research?\n",
    "\n",
    "Although the first two out of the three speculations are unlikely to result from just reading into our two datasets, it would be a waste to not break these chunks of information apart and see what we can get, but before we delve deep into our datasets, we should consider the limitations of our data.\n",
    "\n",
    "1. The Kaggle dataset (\"housing.csv\") is an extracted (but not cleaned) version of the California 1990 Census and it holds median and total numerical values for housing features per district, separated by latitudinal and longitudinal coordinates. Kaggle is an online community platform for data enthusiasts. This dataset is a modified version from data that was gathered by associate professor, Luis Torgo, from the University of Porto, whom of which had collected the data from the California Census of 1990.\n",
    "\n",
    "2. The recent housing listings data (\"Total.csv\"), which were posted from up to a year since 19 September 2018, only shows listings that are posted by real estate brokers on an industry-accepted information dissemination system, the California Regional Multiple Listing Service (CRMLS); therefore, off-market listings <u>are not</u> represented in the data.\n",
    "\n",
    "Although there are some lingering questions that lay underneath our data (considering how it was obtained) and our resources are limited as to how accurately we can produce our analyses, we still are tasked to come to a data-driven conclusion to find out the answer to the following question:\n",
    "\n",
    "If we took the top and bottom five percentiles of houses in California during the 1990s, in terms of median house value, and compared them to houses of the same standing that have been listed for sale within the last year in the same market, would there be a statistical difference between the two groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up and getting our hands dirty with the data\n",
    "Before we can extract any meaningful and accurate analyses from our data, we must first make an attempt to understand all of its facets and not just search for whatever we want; that means, we must first 'get our hands dirty' with it. Although it can be irresistably fun just to mess around with our data, we should be aware that there is a more valuable incentive for doing so, which is described by the XY Problem.\n",
    "\n",
    "** For further reasoning, please refer to the following link to a discussion which details the XY Problem: https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to easily work with our data, we must first import the necessary dependencies and store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import gmplot\n",
    "import scipy as stats\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/store data\n",
    "ca_1990 = pd.read_csv('Data/housing.csv')\n",
    "ca_current = pd.read_csv('Data/Total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total instances are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1990.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's drop the rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1990 = ca_1990.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_1990.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason for dropping values\n",
    "There is an approximate 1% difference when rows with any empty values are dropped and the data is derived as the median of each of its categories per the district; therefore, the values are negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing (1990) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Search for Relationships\n",
    "We were looking at the several features that was listed within our data (such as the longitudinal and latitudinal coordinates of each district, the median ages of the houses, the total number of rooms, and so forth)  and made several charts in an attempt to draw insights which may be lying underneath, and they are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Rooms per District vs Total Population District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "group_names = [\"<5k\", \"5k-10k\", \"10k-15k\", \"15k-20k\", \"20k-25k\", \"25k-30k\", \"30k-35k\", \">35k\"]\n",
    "ca_1990[\"total_rooms_groups\"] = pd.cut(ca_1990['total_rooms'], bins, labels=group_names)\n",
    "\n",
    "plt.scatter(ca_1990['total_rooms_groups'], ca_1990['population'])\n",
    "plt.xlabel('Total Rooms')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Total Rooms per District vs Population per District')\n",
    "plt.grid()\n",
    "plt.savefig(\"pngs/pop_vs_rooms_sub_groups.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The chart above depicts the frequencies for several ranges of number of total rooms per the district and is set against the total population of a district.*\n",
    "* *It is intriguing to see that there is a concentration of districts that have zero to twenty thousand rooms and populations from zero to thirteen thousand.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slice the top 5%\n",
    "top5 = ca_1990.iloc[:round(len(ca_1990['median_house_value'])*0.05), :].sort_values('median_house_value', ascending=False)\n",
    "top5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Five Percent of Median House Values vs Total Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 13000]\n",
    "group_names = [\"<1k\", \"1k-2k\", \"2k-3k\", \"3k-4k\", \"4k-5k\", \"5k-6k\", \"6k-7k\", \">7k\"]\n",
    "top5['population_groups'] = pd.cut(top5['population'], bins, labels=group_names)\n",
    "top5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(top5['median_house_value'], top5['population_groups'], c='r')\n",
    "plt.xlabel('House Value')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Total Population vs Median House Value')\n",
    "plt.savefig(\"pngs/Top5_PHV.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *From the plot above, we can see that there is a general concentration in districts with populations ranging from zero to two thousand people per district, in respect to houses that rank in the top five percentile in terms of median house value.*\n",
    "* *We can infer from this data that districts with this general range of population is ubiquitous and non-dependent of median house value.*\n",
    "* *Intriguingly, we can see that houses that are worth approximately five hundred thousand dollars can vary from small to large numbers of population.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom Five Percent of Median House Values vs Total Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 3000, 6000, 9000, 12000, 15000, 18000]\n",
    "group_names = [\"<3k\", \"3k-6k\", \"6k-9k\", \"9k-12k\", \"12k-15k\", \">15k\"]\n",
    "bottom5[\"population_groups\"] = pd.cut(bottom5['population'], bins, labels=group_names)\n",
    "\n",
    "plt.scatter(bottom5['median_house_value'], bottom5['population_groups'], c='g')\n",
    "plt.xlabel('House Value')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Total Population vs Median House Value')\n",
    "plt.savefig('pngs/Bottom5_PHV.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *From the plot above, we can see that there is a general concentration in districts with populations ranging from zero to three thousand people per district and from three to six thousand people per district, in respect to houses that rank in the bottom five percentile in terms of median house value.*\n",
    "* *We can infer from this data that districts with these general ranges of populations are ubiquitous and non-dependent of median house value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slice the bottom 5%\n",
    "bottom5 = ca_1990.iloc[round(len(ca_1990['median_house_value'])*0.95): len(ca_1990['median_house_value']),:].sort_values('median_house_value', ascending=False)\n",
    "bottom5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ocean Proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort data by house value\n",
    "ca_1990 = ca_1990.sort_values('median_house_value', ascending=False).reset_index(drop=True)\n",
    "ca_1990.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ocean Proximity vs Count of Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_axis_op = [\"<1H OCEAN\", \"INLAND\", \"ISLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
    "y_axis_op = ca_1990.groupby(\"ocean_proximity\").count().rename(columns={\"longitude\": \"count_of_houses\"})[\"count_of_houses\"]\n",
    "plt.bar(x_axis_op, y_axis_op, alpha=0.5, align='center')\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Count of Houses\")\n",
    "op_bar_chart = plt.title(\"Total Number of Houses in CA per OP Category\")\n",
    "plt.savefig('pngs/op_vs_count_of_houses.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The bar chart above depicts the total count of houses per each category.*\n",
    "* *We can see that most of the houses in California are either less than one-hour away from the ocean or are inland.*\n",
    "* *The chart also communicates that the majority of Californians lived less than one hour from the ocean during the 1990s.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Percent Ocean Proximity vs Count of Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_op = [\"<1H OCEAN\", \"INLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
    "y_axis_op = top5.groupby(\"ocean_proximity\").count().rename(columns={\"longitude\": \"count_of_houses\"})[\"count_of_houses\"]\n",
    "plt.bar(x_axis_op, y_axis_op, color='b', alpha=0.5, align='center')\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Count of Houses\")\n",
    "op_bar_chart = plt.title(\"Top Five Percent\")\n",
    "plt.savefig(\"pngs/top_five_op_vs_COH.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The chart above shows the total count of houses per ocean proximity category for houses in the top five percent, in terms of median house value.*\n",
    "* *The majority of these houses are in closer proximity to some body of water than houses that are inland.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom 5 Percent Ocean Proximity vs Count of Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_op = [\"<1H OCEAN\", \"INLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
    "y_axis_op = bottom5.groupby(\"ocean_proximity\").count().rename(columns={\"longitude\": \"count_of_houses\"})[\"count_of_houses\"]\n",
    "plt.bar(x_axis_op, y_axis_op, color='g', alpha=0.5, align='center')\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Count of Houses\")\n",
    "op_bar_chart = plt.title(\"Bottom Five Percent\")\n",
    "plt.savefig(\"pngs/bottom_five_op_vs_COH.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *The chart above depicts the total count of houses per ocean proximity category for houses in the bottom five percent, in terms of median house value.*\n",
    "* *The majority of these houses are inland; furthest from any body of water in comparison to their counterparts.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Five Ocean Proximity Average Median Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_mean_house_value_top = top5.groupby(\"ocean_proximity\")[\"median_house_value\"].mean().round(2)\n",
    "op_mean_df_top = pd.DataFrame(op_mean_house_value_top)\n",
    "op_mean_df_top = op_mean_df_top.rename(columns={\"median_house_value\":\"Average Median Price\"})\n",
    "op_mean_df_top['Average Median Price'] = op_mean_df_top['Average Median Price'].map('${:,.2f}'.format)\n",
    "op_mean_df_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Although we expect that being located closer to bodies of water usually translates to a higher price per house, the averages of the median values for our top five percent of houses in California have similar prices.*\n",
    "* *Intriguingly, the inland category has an average value that is higher than any of the other categories, which are all nearer to some body of water.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom Five Ocean Proximity Average Median Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_mean_house_value_bottom = bottom5.groupby(\"ocean_proximity\")[\"median_house_value\"].mean().round(2)\n",
    "op_mean_df_bottom = pd.DataFrame(op_mean_house_value_bottom)\n",
    "op_mean_df_bottom = op_mean_df_bottom.rename(columns={\"median_house_value\":\"Average Median Price\"})\n",
    "op_mean_df_bottom['Average Median Price'] = op_mean_df_bottom['Average Median Price'].map('${:,.2f}'.format)\n",
    "op_mean_df_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Again, we expect that being located closer to bodies of water would translate to a higher price per house, the averages of the median values for our bottom five percent of houses in California deviates from our assumptions.*\n",
    "* *The same surprise is evident in this data, when compared to its opposite counterpart.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing (2018) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns that are useful \n",
    "ca_current = ca_current[['Sub Type', 'St#', 'St Name', 'City', 'L/C Price', 'Br/Ba', 'YrBuilt']]\n",
    "ca_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *We cleaned our data frame of any superfluous information, as either some are not quantifiable or we simply cannot work with them due to our limited sets of data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Housing Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating for the age, we must check for any missing values that lay in our YrBuilt column and the count of all instances in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in ca_current['YrBuilt'].isna():\n",
    "    if i == True:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_current.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ca_current.count().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also must calculate the number of values dropped if we were to delete all rows with any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_current.dropna().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Here, we encounter something strange. Even though our for loop above states that there are 8 NaN values underneath the YrBuilt columns, when we drop all rows with any missing value, the total number of rows dropped is only 4.*\n",
    "* *If we continue to attempt with a new dataframe that utilizes the .dropna() method, we will find that there is a bug in which most values become missing; therefore, we must fill all missing values with 0 in order to solve our issue.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the string to isolate the integers\n",
    "yr_blt = ca_current.loc[:, 'YrBuilt'].str.split('/', expand=True)[0]\n",
    "# Turn the values into a data frame\n",
    "yr_blt = pd.DataFrame(yr_blt)\n",
    "# Fill the empty cells with 0\n",
    "yr_blt = yr_blt.fillna(0)\n",
    "# Create the new columns for age\n",
    "ca_current['Age'] = ''\n",
    "# Calculate for age\n",
    "count = 0\n",
    "for i in yr_blt[0]:\n",
    "    # Values that were empty are now 0 years old.\n",
    "    # We will count them later to determine whether or not we will drop them.\n",
    "    i = 2018 - int(i)\n",
    "    ca_current['Age'][count] = i\n",
    "    count += 1\n",
    "ca_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *In the data frame above, we are calculating the current ages of our houses by subtracting the current year from the year they were built.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of NaN Values under YrBuilt column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grab all values with the year 2018 since 2018 - 0 = 2018\n",
    "with_nan_df = ca_current.loc[ca_current['Age'] == 2018, :]\n",
    "# Grab the values that are not NaN, but built in 2018\n",
    "zero_bld = with_nan_df.loc[with_nan_df['YrBuilt'] == '0/BLD', :]\n",
    "zero_asr = with_nan_df.loc[with_nan_df['YrBuilt'] == '0/ASR', :]\n",
    "# Remove the houses that are built in 2018 and merge the necessary data frames\n",
    "without_2018_df = pd.merge(ca_current, with_nan_df, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "with_zero_bld = pd.merge(without_2018_df, zero_bld, how='outer')\n",
    "zero_asr['Age'] = zero_asr['Age'].apply(int)\n",
    "without_nan_df = pd.merge(with_zero_bld, zero_asr, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the house prices without the dollar sign \n",
    "without_nan_df['house_price'] = without_nan_df.loc[:, 'L/C Price'].str.split('$', expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(without_nan_df['Age'], without_nan_df['house_price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 100000, 500000, 1000000, 3000000, 5000000]\n",
    "group_names = [\"0-100k\", \"100k-500k\", \"500k-1M\", \"1M-3M\", \"3M-5M\"]\n",
    "#without_nan_df['house_price_group'] =\n",
    "#pd.cut(without_nan_df['house_price'], bins, labels=group_names)\n",
    "#without_nan_df['house_price'] = pd.to_numeric(\n",
    "without_nan_df['house_price'] = without_nan_df['house_price'].str.split(expand=True)[0]\n",
    "for i in without_nan_df['house_price']:\n",
    "    i = int(i)\n",
    "#plt.scatter(without_nan_df['Age'], without_nan_df['house_price_group'], c='r')\n",
    "#plt.xlabel('House Value')\n",
    "#plt.ylabel('Population')\n",
    "#plt.title('Total Population vs Median House Value')\n",
    "#plt.savefig(\"pngs/Top5_PHV.png\", dpi=300)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(without_nan_df['Age'], without_nan_df['house_price'], c='#17DD00')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Age vs Price of House')\n",
    "plt.grid()\n",
    "plt.savefig('pngs/age_vs_price_plt', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data frame and set the index to the listing price\n",
    "sorted_ca_current = ca_current.set_index(\"L/C Price\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort data by median house value and slice the top and bottom 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the top 5%\n",
    "top5_2018 = sorted_ca_current.iloc[round(len(sorted_ca_current['house_price'])*0.95): len(sorted_ca_current['house_price']),:]\n",
    "top5_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the bottom 5%\n",
    "bottom5_2018 = sorted_ca_current.iloc[:round(len(sorted_ca_current['house_price'])*0.05), :]\n",
    "bottom5_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test on 1990 house value and 2018 house value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
